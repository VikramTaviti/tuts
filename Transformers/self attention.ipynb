{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1a0fa6e-82f8-47e6-a668-ecddb1497430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "713f107d-4426-4105-ac21-d6797640dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define input embeddings (3 tokens, 2d)\n",
    "#assume these 2 dimentions of word embeddings capture two features like(Gender,DC)\n",
    "tokens = ['I', 'am', 'Batman']\n",
    "X = np.array([\n",
    "    [1.0, 0.0],  \n",
    "    [0.0, 0.0],  \n",
    "    [0.0, 1.0]   \n",
    "])\n",
    "\n",
    "\n",
    "#In BERT it is 768 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc362767-f841-447a-9c59-8330b9661b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define weights, which can be learned while training(back propagation..)\n",
    "W_q = np.array([[1.0, 2.0],     #--> Query weights\n",
    "                [3.0, 4.0]])\n",
    "\n",
    "W_k = np.array([[0.5, 1.0],    # ---> Key weights\n",
    "                [1.5, 1.0]])\n",
    "\n",
    "W_v = np.array([[1.0, 0.5],    # ---> Values weights\n",
    "                [0.5, 1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aae3ef1f-92b9-455d-892e-c249422abd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3 get Q,K,V from weights..\n",
    "Q = X @ W_q.T   #Transpose because to match column number of embeddings to row number of weights for to get the shape (n_rows, n_weights) \n",
    "K = X @ W_k.T \n",
    "V = X @ W_v.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "501d3a71-3ffd-4554-bfef-232d2d51408b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 3.],\n",
       "       [0., 0.],\n",
       "       [2., 4.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c890611-90c7-499a-8b9a-303bb7a25139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 1.5],\n",
       "       [0. , 0. ],\n",
       "       [1. , 1. ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bb7be18-1540-42cb-9d3b-4d17409efc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compute attention scores (Q @ K.T)\n",
    "scores = Q @ K.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9af7f65a-be06-41bf-bb3e-673597948731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 4.],\n",
       "       [0., 0., 0.],\n",
       "       [7., 0., 6.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cce5de-60a9-485c-ae08-b63592df8c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "defc6627-d559-4507-9268-9457e167d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Scale the scores\n",
    "d_k = Q.shape[1]\n",
    "scaled_scores = scores / np.sqrt(d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e3f41de-7325-44eb-b74a-fe9e0c25ca8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.53553391, 0.        , 2.82842712],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [4.94974747, 0.        , 4.24264069]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce79b4fc-705d-469e-9677-7e0d83338737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Apply softmax row-wise\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))  # stability trick\n",
    "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
    "\n",
    "attention_weights = np.apply_along_axis(softmax, axis=1, arr=scaled_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca030cad-a0df-421c-a9d5-69f4c7a755af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65693877, 0.01914529, 0.32391594],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.66659828, 0.00472298, 0.32867874]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27a41b32-9584-4982-ae9b-a7932a5ae532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Weighted sum of V using attention weights\n",
    "output = attention_weights @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d437170-eb06-4e43-a5f6-ee5cafb9fd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0.5],\n",
       "       [0. , 0. ],\n",
       "       [0.5, 1. ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b5a69a9-dc7a-426a-ab9b-33a9b83c8e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81889674, 0.65238532],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.83093765, 0.66197788]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fa00a71-c304-40ea-9a81-ccba2bbe18d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens:       ['I', 'am', 'Batman']\n",
      "Q:\n",
      " [[1. 3.]\n",
      " [0. 0.]\n",
      " [2. 4.]]\n",
      "K:\n",
      " [[0.5 1.5]\n",
      " [0.  0. ]\n",
      " [1.  1. ]]\n",
      "V:\n",
      " [[1.  0.5]\n",
      " [0.  0. ]\n",
      " [0.5 1. ]]\n",
      "Attention scores:\n",
      " [[3.53553391 0.         2.82842712]\n",
      " [0.         0.         0.        ]\n",
      " [4.94974747 0.         4.24264069]]\n",
      "Attention weights:\n",
      " [[0.65693877 0.01914529 0.32391594]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.66659828 0.00472298 0.32867874]]\n",
      "Self-attention output:\n",
      " [[0.81889674 0.65238532]\n",
      " [0.5        0.5       ]\n",
      " [0.83093765 0.66197788]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Input tokens:      \", tokens)\n",
    "print(\"Q:\\n\", Q)\n",
    "print(\"K:\\n\", K)\n",
    "print(\"V:\\n\", V)\n",
    "print(\"Attention scores:\\n\", scaled_scores)\n",
    "print(\"Attention weights:\\n\", attention_weights)\n",
    "print(\"Self-attention output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d260af-555f-4e49-97f9-2f1cc03e579f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065be525-5ba6-432a-a467-d45d0165e440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
